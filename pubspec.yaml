name: llama
description: "llama is a dart implementation of llama.cpp used by the mobile artificial intelligence distribution (maid)"
version: 0.0.1
homepage: "https://github.com/Mobile-Artificial-Intelligence/llama_dart"

environment:
  sdk: '>=3.3.0 <4.0.0'
  flutter: '>=3.3.0'

dependencies:
  ffi: ^2.1.3
  flutter:
    sdk: flutter

dev_dependencies:
  ffigen: ^11.0.0
  flutter_test:
    sdk: flutter
  flutter_lints: ^3.0.0

ffigen:
  name: 'llama'
  description: 'llama.cpp binding'
  output: 'lib/bindings.dart'
  ignore-source-errors: true
  headers:
    entry-points:
      - 'src/api.h'
      - 'src/llama_cpp/include/llama.h'
      - 'src/llama_cpp/ggml/include/ggml.h'
      - 'src/llama_cpp/ggml/include/ggml-cpu.h'
      - 'src/llama_cpp/ggml/include/ggml-backend.h'
  compiler-opts:
    - '-I/usr/lib/clang/17/include'

# For information on the generic Dart part of this file, see the
# following page: https://dart.dev/tools/pub/pubspec

# The following section is specific to Flutter packages.
flutter:
  plugin:
    platforms:
      android:
        ffiPlugin: true
      linux:
        ffiPlugin: true
      windows:
        ffiPlugin: true
      macos:
        ffiPlugin: true
